{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import keras\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 0.jpg\n",
      "Image format: JPEG\n",
      "Image size: (60, 40)\n",
      "Image mode: L\n"
     ]
    }
   ],
   "source": [
    "directory = \"Dataset/0\"\n",
    "images = []\n",
    "\n",
    "def preprocess_image(image_path, target_size):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize(target_size)\n",
    "    image = np.array(image) / 255.0  # Normalize pixel values to [0, 1]\n",
    "    return image\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the file is an image (you might want to improve this check)\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Construct the full path to the image file\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        image = Image.open(filepath)\n",
    "        print(\"Image:\", filename)\n",
    "        print(\"Image format:\", image.format)\n",
    "        print(\"Image size:\", image.size)\n",
    "        print(\"Image mode:\", image.mode)\n",
    "        image = preprocess_image(filepath, target_size=(60,40))\n",
    "        images.append(image)\n",
    "        break\n",
    "\n",
    "\n",
    "# # Path to your JSON file\n",
    "# json_file_path = \"BallSimSample\\data.json\"\n",
    "# df = pd.read_json(json_file_path)\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>car_positions</th>\n",
       "      <th>car_velocities</th>\n",
       "      <th>ball_in_frames</th>\n",
       "      <th>ball_positions</th>\n",
       "      <th>ball_velocities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[[2.966482266153105, 3.027535346713439, 3.0876...</td>\n",
       "      <td>[[0.29231126032610155, 0.28769300499707195, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[[4.406167965707559, 4.457454497927218, 4.5075...</td>\n",
       "      <td>[[0.2464564468427059, 0.24076560924405016, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[[5.288511802797698, 5.4255085884006995, 5.560...</td>\n",
       "      <td>[[0.6563893731302016, 0.6450800900983077, 0.63...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[[4.145333906935041, 4.174442777541345, 4.2025...</td>\n",
       "      <td>[[0.14068958460443076, 0.13584468615545922, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[[2.827627505129355, 2.7414890450588323, 2.657...</td>\n",
       "      <td>[[-0.41343995805969874, -0.4048754126102626, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              images  \\\n",
       "0  [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
       "1  [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
       "2  [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
       "3  [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
       "4  [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
       "\n",
       "                                       car_positions  \\\n",
       "0  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
       "1  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
       "2  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
       "3  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
       "4  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
       "\n",
       "                                      car_velocities  \\\n",
       "0  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
       "1  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
       "2  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
       "3  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
       "4  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
       "\n",
       "                   ball_in_frames  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                      ball_positions  \\\n",
       "0  [[2.966482266153105, 3.027535346713439, 3.0876...   \n",
       "1  [[4.406167965707559, 4.457454497927218, 4.5075...   \n",
       "2  [[5.288511802797698, 5.4255085884006995, 5.560...   \n",
       "3  [[4.145333906935041, 4.174442777541345, 4.2025...   \n",
       "4  [[2.827627505129355, 2.7414890450588323, 2.657...   \n",
       "\n",
       "                                     ball_velocities  \n",
       "0  [[0.29231126032610155, 0.28769300499707195, 0....  \n",
       "1  [[0.2464564468427059, 0.24076560924405016, 0.2...  \n",
       "2  [[0.6563893731302016, 0.6450800900983077, 0.63...  \n",
       "3  [[0.14068958460443076, 0.13584468615545922, 0....  \n",
       "4  [[-0.41343995805969874, -0.4048754126102626, -...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_json(json_file, img_folder):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    length = len(data) - 1\n",
    "    print(length)\n",
    "    # Extract data for each sample\n",
    "    img_files = [data[str(i)][\"img_file\"] for i in range(length)]\n",
    "    car_positions = [data[str(i)][\"car_pos\"] for i in range(length)]\n",
    "    car_velocities = [data[str(i)][\"car_vel\"] for i in range(length)]\n",
    "    ball_in_frames = [data[str(i)][\"ball_in_frame\"] for i in range(length)]\n",
    "    ball_positions = data[\"ball_trj\"][\"pos\"]\n",
    "    ball_velocities = data[\"ball_trj\"][\"vel\"]\n",
    "    \n",
    "    # Load and store images\n",
    "    images = []\n",
    "    for i, img_file in enumerate(img_files):\n",
    "        img_path = os.path.join(img_folder, img_file)\n",
    "        # print(img_path)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            # Convert image to numpy array and normalize\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            images.append(img)\n",
    "            # print(\"SUCCESS\")\n",
    "        else:\n",
    "            print(f\"Error loading image: {img_path}\")\n",
    "    \n",
    "    # Convert images to numpy array\n",
    "    images = np.array(images)\n",
    "    \n",
    "    # Create a dictionary with the extracted data\n",
    "    sample_data = {\n",
    "        'images': images,\n",
    "        'car_positions': car_positions,\n",
    "        'car_velocities': car_velocities,\n",
    "        'ball_in_frames': ball_in_frames,\n",
    "        'ball_positions': ball_positions,\n",
    "        'ball_velocities': ball_velocities\n",
    "    }\n",
    "    \n",
    "    return sample_data\n",
    "\n",
    "def create_dataframe_from_folders(json_root_folder, img_folder):\n",
    "    # Initialize an empty list to hold data for all samples\n",
    "    all_samples_data = []\n",
    "    \n",
    "    # Iterate over subfolders in the root JSON folder\n",
    "    for i, folder in enumerate(os.listdir(json_root_folder)):\n",
    "        folder_path = os.path.join(json_root_folder, folder)\n",
    "        # print(folder_path)\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Initialize an empty list to hold data for the current sample\n",
    "            sample_data = process_json(os.path.join(folder_path, 'data.json'), img_folder+str(i))\n",
    "            \n",
    "            # Append the data for the current sample to the list of all samples\n",
    "            all_samples_data.append(sample_data)\n",
    "    \n",
    "    # Create DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(all_samples_data)\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "json_root_folder = 'Dataset'\n",
    "img_folder = 'Dataset/'\n",
    "df = create_dataframe_from_folders(json_root_folder, img_folder)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# first_image = df['images'][89]\n",
    "# for i in range(len(first_image)):\n",
    "#     # Convert the current image to uint8 (required by cv2.imshow())\n",
    "#     current_image = (first_image[i] * 255).astype('uint8')\n",
    "#     # Display the current image\n",
    "#     cv2.imshow(f'Image {i+1}', current_image)\n",
    "#     # Wait for a key press\n",
    "#     cv2.waitKey(0)\n",
    "\n",
    "# # Close all OpenCV windows\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               images  \\\n",
      "0   [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
      "1   [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
      "2   [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
      "3   [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
      "4   [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
      "..                                                ...   \n",
      "75  [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
      "76  [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
      "77  [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
      "78  [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
      "79  [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...   \n",
      "\n",
      "                                        car_positions  \\\n",
      "0   [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
      "1   [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
      "2   [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
      "3   [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
      "4   [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
      "..                                                ...   \n",
      "75  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
      "76  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
      "77  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
      "78  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
      "79  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...   \n",
      "\n",
      "                                       car_velocities  \n",
      "0   [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...  \n",
      "1   [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...  \n",
      "2   [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...  \n",
      "3   [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...  \n",
      "4   [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...  \n",
      "..                                                ...  \n",
      "75  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...  \n",
      "76  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...  \n",
      "77  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...  \n",
      "78  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...  \n",
      "79  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0...  \n",
      "\n",
      "[80 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df contains your DataFrame with all the data\n",
    "# Specify the features and target variable\n",
    "X = df[['images', 'car_positions', 'car_velocities']]\n",
    "y = df[['ball_positions', 'ball_velocities']]\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optionally, you can reset the index for the splits if needed\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "print(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_input (InputLayer)       [(None, 10, 40, 60,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " model_5 (Functional)           (None, 6656)         57984       ['image_input[0][0]']            \n",
      "                                                                                                  \n",
      " velocity_input (InputLayer)    [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " position_input (InputLayer)    [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 6676)         0           ['model_5[0][0]',                \n",
      "                                                                  'velocity_input[0][0]',         \n",
      "                                                                  'position_input[0][0]']         \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          854656      ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 2)            258         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 912,898\n",
      "Trainable params: 912,898\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv3D, MaxPooling3D, Flatten, Dense, concatenate\n",
    "from keras.models import Model\n",
    "num_images = 10\n",
    "image_height = 40\n",
    "image_width = 60 \n",
    "num_channels = 3\n",
    "num_classes = 2\n",
    "# Image input\n",
    "image_input = Input(shape=(num_images, image_height, image_width, num_channels), name='image_input')\n",
    "conv1 = Conv3D(32, kernel_size=(3, 3, 3), activation='relu')(image_input)  # Use Conv3D for 3D convolution\n",
    "maxpool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)  # Use MaxPooling3D for 3D max pooling\n",
    "conv2 = Conv3D(64, kernel_size=(3, 3, 3), activation='relu')(maxpool1)\n",
    "maxpool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "flatten_image = Flatten()(maxpool2)\n",
    "\n",
    "# Velocity and position input\n",
    "velocity_input = Input(shape=(10,), name='velocity_input')\n",
    "position_input = Input(shape=(10,), name='position_input')\n",
    "\n",
    "# CNN branch for image processing\n",
    "image_branch = Model(inputs=image_input, outputs=flatten_image)\n",
    "\n",
    "# Get output from image branch\n",
    "image_features = image_branch(image_input)\n",
    "\n",
    "# Combined feature extraction\n",
    "combined = concatenate([image_features, velocity_input, position_input])\n",
    "\n",
    "# Dense layers for further processing\n",
    "dense1 = Dense(128, activation='relu')(combined)\n",
    "output = Dense(num_classes, activation='softmax')(dense1)\n",
    "\n",
    "# Define model with multiple inputs\n",
    "model = Model(inputs=[image_input, velocity_input, position_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy', 'precision'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='velocity_input'), name='velocity_input', description=\"created by layer 'velocity_input'\"), but it was called on an input with incompatible shape (None, 10, 2).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='position_input'), name='position_input', description=\"created by layer 'position_input'\"), but it was called on an input with incompatible shape (None, 10, 2).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\AznNo\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\AznNo\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\AznNo\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\AznNo\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\AznNo\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\AznNo\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py\", line 3572, in concatenate\n        return tf.concat([to_dense(x) for x in tensors], axis)\n\n    ValueError: Exception encountered when calling layer \"concatenate_3\" \"                 f\"(type Concatenate).\n    \n    Shape must be rank 2 but is rank 3 for '{{node model_6/concatenate_3/concat}} = ConcatV2[N=3, T=DT_FLOAT, Tidx=DT_INT32](model_6/model_5/flatten_3/Reshape, IteratorGetNext:1, IteratorGetNext:2, model_6/concatenate_3/concat/axis)' with input shapes: [?,6656], [?,10,2], [?,10,2], [].\n    \n    Call arguments received by layer \"concatenate_3\" \"                 f\"(type Concatenate):\n      • inputs=['tf.Tensor(shape=(None, 6656), dtype=float32)', 'tf.Tensor(shape=(None, 10, 2), dtype=float32)', 'tf.Tensor(shape=(None, 10, 2), dtype=float32)']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m ball_velocities_tf \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(y_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mball_velocities\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Fit the model with multiple outputs\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimages_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcar_positions_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcar_velocities_tf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mball_positions_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mball_velocities_tf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\AznNo\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filewxr72bd7.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\AznNo\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\AznNo\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\AznNo\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\AznNo\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\AznNo\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\AznNo\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py\", line 3572, in concatenate\n        return tf.concat([to_dense(x) for x in tensors], axis)\n\n    ValueError: Exception encountered when calling layer \"concatenate_3\" \"                 f\"(type Concatenate).\n    \n    Shape must be rank 2 but is rank 3 for '{{node model_6/concatenate_3/concat}} = ConcatV2[N=3, T=DT_FLOAT, Tidx=DT_INT32](model_6/model_5/flatten_3/Reshape, IteratorGetNext:1, IteratorGetNext:2, model_6/concatenate_3/concat/axis)' with input shapes: [?,6656], [?,10,2], [?,10,2], [].\n    \n    Call arguments received by layer \"concatenate_3\" \"                 f\"(type Concatenate):\n      • inputs=['tf.Tensor(shape=(None, 6656), dtype=float32)', 'tf.Tensor(shape=(None, 10, 2), dtype=float32)', 'tf.Tensor(shape=(None, 10, 2), dtype=float32)']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert NumPy arrays to TensorFlow tensors\n",
    "print(type(X_train['images']))\n",
    "images_tf = tf.convert_to_tensor(X_train['images'].tolist())\n",
    "car_positions_tf = tf.convert_to_tensor(X_train['car_positions'].tolist())\n",
    "car_velocities_tf = tf.convert_to_tensor(X_train['car_velocities'].tolist())\n",
    "ball_positions_tf = tf.convert_to_tensor(y_train['ball_positions'].tolist())\n",
    "ball_velocities_tf = tf.convert_to_tensor(y_train['ball_velocities'].tolist())\n",
    "\n",
    "# Fit the model with multiple outputs\n",
    "model.fit([images_tf, car_positions_tf, car_velocities_tf], [ball_positions_tf, ball_velocities_tf], epochs=100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 2.4124 - accuracy: 0.1667\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.0205 - accuracy: 0.1667\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.6251 - accuracy: 0.1667\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2713 - accuracy: 0.3333\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9752 - accuracy: 0.3333\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7433 - accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5600 - accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3045 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2196 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1578 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1128 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0600 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0449 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024DF8D76310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[0.00122195]\n",
      " [0.00632339]\n",
      " [0.00611844]\n",
      " [0.0025177 ]\n",
      " [0.00313826]\n",
      " [0.0053585 ]\n",
      " [0.00654464]\n",
      " [0.00412661]\n",
      " [0.0013232 ]\n",
      " [0.00017696]]\n",
      "Predicted collision: Yes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Sample trajectory data for two objects\n",
    "data = np.array([\n",
    "    [0, 0, 0, 5, 7, 0, -9.8, 10, 10, 2, 3, 0, -9.8],\n",
    "    [1, 5, 7, 5, -2, 0, -9.8, 12, 13, 2, -1, 0, -9.8],\n",
    "    [2, 10, 5, 5, -11, 0, -9.8, 14, 12, 2, -5, 0, -9.8],\n",
    "    [3, 15, -6, 5, -20, 0, -9.8, 16, 7, 2, -10, 0, -9.8],\n",
    "    [4, 20, -26, 5, -29, 0, -9.8, 18, -3, 2, -15, 0, -9.8],\n",
    "    [5, 25, -55, 5, -38, 0, -9.8, 20, -20, 2, -20, 0, -9.8]\n",
    "])\n",
    "\n",
    "# Function to check for collision between two objects\n",
    "def check_collision(obj1_pos, obj2_pos):\n",
    "    return np.sqrt((obj1_pos[0] - obj2_pos[0])**2 + (obj1_pos[1] - obj2_pos[1])**2) < 2  # Assuming collision if distance < 2 units\n",
    "\n",
    "# Split data into input features and labels for both objects\n",
    "X = data[:, 1:]  # Features: position, velocity, acceleration for both objects\n",
    "y = np.array([check_collision(data[i, 1:3], data[i, 7:9]) for i in range(len(data))])  # Labels: collision (1) or no collision (0)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(12,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output layer with 1 unit for binary classification (collision or no collision)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, verbose=1)\n",
    "\n",
    "# Predict collision for a new input\n",
    "new_input = np.array([\n",
    "    [0, 0, 5, 7, 0, -9.8, 10, 10, 2, 3, 0, -9.8],\n",
    "    [1, 5, 5, -2, 0, -9.8, 12, 13, 2, -1, 0, -9.8],\n",
    "    [2, 10, 5, -11, 0, -9.8, 14, 12, 2, -5, 0, -9.8],\n",
    "    [3, 15, 5, -20, 0, -9.8, 16, 7, 2, -10, 0, -9.8],\n",
    "    [4, 20, 5, -29, 0, -9.8, 18, -3, 2, -15, 0, -9.8],\n",
    "    [5, 25, 5, -38, 0, -9.8, 20, -20, 2, -20, 0, -9.8],\n",
    "    [6, 30, 5, -47, 0, -9.8, 22, -40, 2, -25, 0, -9.8],\n",
    "    [7, 35, 5, -56, 0, -9.8, 24, -63, 2, -30, 0, -9.8],\n",
    "    [8, 40, 5, -65, 0, -9.8, 26, -90, 2, -35, 0, -9.8],\n",
    "    [9, 45, 5, -74, 0, -9.8, 28, -121, 2, -40, 0, -9.8]\n",
    "]) # New input features for both objects\n",
    "predicted_collision = model.predict(new_input)\n",
    "print(predicted_collision)\n",
    "if predicted_collision.any() < 0.5:\n",
    "    print(\"Predicted collision: No\")\n",
    "else:\n",
    "    print(\"Predicted collision: Yes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
